{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM625qwMAh9uKCamDCYAHDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikolayspb1981/NFTs-Upload-to-OpenSea/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1) Установка зависимостей\n",
        "!pip install pycuda coincurve bloom-filter2 pycryptodome\n",
        "\n",
        "# 2) Монтируем диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 3) Импорты\n",
        "import os, time, hashlib\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "from coincurve import PrivateKey\n",
        "from Crypto.Hash import RIPEMD160\n",
        "from bloom_filter2 import BloomFilter\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# 4) Конфиг\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/Puzzle71\"\n",
        "FILE_NAME    = \"Puzzle 71.013.000.csv\"\n",
        "FILE_PATH    = os.path.join(DRIVE_FOLDER, FILE_NAME)\n",
        "\n",
        "SCAN_RANGE        = 100_000\n",
        "TARGET_PREFIX     = bytes.fromhex(\"f6f543\")\n",
        "KNOWN_H160S       = [bytes.fromhex(\"f6f5431d25bbf7b12e8add9af5e3475c44a0a5b8\")]\n",
        "BLOOM_CAPACITY    = 1_000_000\n",
        "BLOOM_ERROR_RATE  = 0.001\n",
        "SECP256K1_ORDER   = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141\n",
        "\n",
        "# Bloom-фильтр\n",
        "bloom = BloomFilter(max_elements=BLOOM_CAPACITY, error_rate=BLOOM_ERROR_RATE)\n",
        "for h in KNOWN_H160S:\n",
        "    bloom.add(h)\n",
        "\n",
        "# Чтение CSV\n",
        "with open(FILE_PATH, 'r') as f:\n",
        "    lines = [ln.strip() for ln in f if ln.strip()]\n",
        "if lines and lines[0].lower().startswith(\"value\"):\n",
        "    lines = lines[1:]\n",
        "decimals = [int(ln) for ln in lines]\n",
        "\n",
        "# CUDA-ядро (заготовка) для SHA256 + RIPEMD160\n",
        "# Нужно вставить сюда вашу реализацию ECC->pubkey и RIPEMD160\n",
        "cuda_src = \"\"\"\n",
        "#include <stdint.h>\n",
        "extern \"C\" {\n",
        "__global__ void hash160_kernel(const uint8_t *pubkeys, uint8_t *out, int num_keys) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= num_keys) return;\n",
        "\n",
        "    // 1) Берём 33-байтный compressed pubkey:\n",
        "    const uint8_t *pk = pubkeys + idx*33;\n",
        "\n",
        "    // 2) SHA256(pk) → tmp[32]\n",
        "    //    (Здесь нужен ваш SHA256-kernel или вызов внешней lib)\n",
        "    uint8_t tmp[32];\n",
        "    // ... fill tmp ...\n",
        "\n",
        "    // 3) RIPEMD160(tmp) → out[idx*20..]\n",
        "    //    (Здесь ваша RIPEMD-kernel)\n",
        "    uint8_t *h160 = out + idx*20;\n",
        "    // ... fill h160 ...\n",
        "}\n",
        "}\n",
        "\"\"\"\n",
        "mod = SourceModule(cuda_src)\n",
        "hash160_kernel = mod.get_function(\"hash160_kernel\")\n",
        "\n",
        "def gpu_batch_hash(pubkeys: bytes) -> bytes:\n",
        "    \"\"\"\n",
        "    Передаём подряд N*33-байтных compressed-ключей, получаем N*20 байт H160.\n",
        "    \"\"\"\n",
        "    num = len(pubkeys)//33\n",
        "    # Выделяем GPU-память\n",
        "    d_pub = cuda.mem_alloc(len(pubkeys))\n",
        "    d_out = cuda.mem_alloc(num*20)\n",
        "    cuda.memcpy_htod(d_pub, pubkeys)\n",
        "\n",
        "    # Запускаем ядро\n",
        "    block, grid = 256, (num+255)//256\n",
        "    hash160_kernel(d_pub, d_out, np.int32(num), block=(block,1,1), grid=(grid,1))\n",
        "\n",
        "    # Скачиваем результат\n",
        "    h160_all = bytearray(num*20)\n",
        "    cuda.memcpy_dtoh(h160_all, d_out)\n",
        "    return bytes(h160_all)\n",
        "\n",
        "def process_decimal(decimal: int):\n",
        "    # Ограничиваем диапазон [1, ORDER-1]\n",
        "    start = max(1, decimal - SCAN_RANGE)\n",
        "    end   = min(decimal + SCAN_RANGE, SECP256K1_ORDER - 1)\n",
        "    if start > end:\n",
        "        print(f\"Decimal {decimal} вне допустимого диапазона — пропускаем\")\n",
        "        return\n",
        "\n",
        "    # Генерируем все compressed-паблики подряд\n",
        "    pubkeys = bytearray((end-start+1)*33)\n",
        "    for i, k in enumerate(range(start, end+1)):\n",
        "        priv = PrivateKey.from_int(k)\n",
        "        pk  = priv.public_key.format(compressed=True)\n",
        "        pubkeys[i*33:(i+1)*33] = pk\n",
        "\n",
        "    t0 = time.time()\n",
        "    # Вычисляем на GPU\n",
        "    h160_all = gpu_batch_hash(bytes(pubkeys))\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    # Проходим по результатам и проверяем префикс/Bloom\n",
        "    matches = []\n",
        "    for i in range((end-start+1)):\n",
        "        h160 = h160_all[i*20:(i+1)*20]\n",
        "        if h160.startswith(TARGET_PREFIX) or h160 in bloom:\n",
        "            matches.append((start+i, h160.hex()))\n",
        "\n",
        "    for k, h in matches:\n",
        "        print(f\"**MATCH!** key={hex(k)} → {h}\")\n",
        "    print(f\"Processed {end-start+1} keys via GPU in {dt:.2f}s ({(end-start+1)/dt:.0f} k/s)\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    print(f\"Запуск на {len(decimals)} значениях, ±{SCAN_RANGE}\")\n",
        "    for dec in decimals:\n",
        "        process_decimal(dec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bve_KYzJTu6A",
        "outputId": "ac0fb576-e5c7-442e-8b59-cfbac77c65fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: coincurve in /usr/local/lib/python3.11/dist-packages (21.0.0)\n",
            "Requirement already satisfied: bloom-filter2 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (3.23.0)\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n",
            "Downloading pytools-2025.1.5-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660427 sha256=5da30bbb27c5c2121e3afc306adf9d89705b32564d2e19b7002c2454bbcd689d\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1 pytools-2025.1.5 siphash24-1.7\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-492fbe5ba343>:68: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "kernel.cu(10): warning #177-D: variable \"pk\" was declared but never referenced\n",
            "      const uint8_t *pk = pubkeys + idx*33;\n",
            "                     ^\n",
            "\n",
            "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "kernel.cu(14): warning #177-D: variable \"tmp\" was declared but never referenced\n",
            "      uint8_t tmp[32];\n",
            "              ^\n",
            "\n",
            "kernel.cu(19): warning #177-D: variable \"h160\" was declared but never referenced\n",
            "      uint8_t *h160 = out + idx*20;\n",
            "               ^\n",
            "\n",
            "\n",
            "  mod = SourceModule(cuda_src)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск на 1000 значениях, ±100000\n",
            "Processed 200001 keys via GPU in 0.02s (11829495 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17654740 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17799716 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17404560 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17311177 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (14693472 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17099802 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (18128998 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17580003 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17645456 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (17328341 k/s)\n",
            "Processed 200001 keys via GPU in 0.01s (14999016 k/s)\n"
          ]
        }
      ]
    }
  ]
}